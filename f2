import cv2
import mediapipe as mp
from controller import Robot, Keyboard, Motion

class Nao(Robot):
    def __init__(self):
        Robot.__init__(self)
        self.findAndEnableDevices()  # Setup necessary robot devices
        self.loadMotionFiles()  # Load motion files (even though we're not using them here)

        # Initialize Mediapipe for pose tracking (no hand tracking needed)
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)
        self.mp_draw = mp.solutions.drawing_utils
        self.cap = cv2.VideoCapture(0)

    def loadMotionFiles(self):
        # If you need motions for future use, leave them here; otherwise, you can remove them
        self.forwards = Motion('../../motions/Forwards50.motion')
        self.backwards = Motion('../../motions/Backwards.motion')
        self.sideStepLeft = Motion('../../motions/SideStepLeft.motion')
        self.sideStepRight = Motion('../../motions/SideStepRight.motion')
        self.turnLeft60 = Motion('../../motions/TurnLeft60.motion')
        self.turnRight60 = Motion('../../motions/TurnRight60.motion')
        self.taiChi = Motion('../../motions/TaiChi.motion')
        self.wipeForhead = Motion('../../motions/WipeForehead.motion')

    def findAndEnableDevices(self):
        self.timeStep = int(self.getBasicTimeStep())
        
        # Enable necessary devices (camera and keyboard for this task)
        self.cameraTop = self.getDevice("CameraTop")
        self.cameraTop.enable(4 * self.timeStep)
        self.keyboard = self.getKeyboard()
        self.keyboard.enable(10 * self.timeStep)

        # Enable motors for shoulder control
        self.RShoulderPitch = self.getDevice("RShoulderPitch")
        self.LShoulderPitch = self.getDevice("LShoulderPitch")
        self.RHipPitch = self.getDevice("RHipPitch")
        self.LHipPitch = self.getDevice("LHipPitch")
        
    def setNeutralArmPositions(self):
        # Set the shoulders to their neutral (resting) position
        self.RShoulderPitch.setPosition(0)  # Neutral position for right shoulder
        self.LShoulderPitch.setPosition(0)  # Neutral position for left shoulder

    def detectPoseGestures(self):
        ret, frame = self.cap.read()
        if not ret:
            return
    
        frame = cv2.flip(frame, 1)  # Mirror the frame horizontally
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result_pose = self.pose.process(frame_rgb)
    
        if result_pose.pose_landmarks:
            # Right shoulder and wrist landmarks (for left-hand movement)
            right_shoulder = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
            right_wrist = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_WRIST]
            # Calculate right shoulder angle (for the robot's left shoulder)
            right_shoulder_angle = (right_wrist.y - right_shoulder.y) * 3  # Scaling factor
            right_shoulder_angle = max(min(right_shoulder_angle, self.LShoulderPitch.getMaxPosition()), self.LShoulderPitch.getMinPosition())
            self.LShoulderPitch.setPosition(right_shoulder_angle)  # Control left shoulder to mirror right hand
    
            # Left shoulder and wrist landmarks (for right-hand movement)
            left_shoulder = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
            left_wrist = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_WRIST]
            # Calculate left shoulder angle (for the robot's right shoulder)
            left_shoulder_angle = (left_wrist.y - left_shoulder.y) * 3  # Scaling factor
            left_shoulder_angle = max(min(left_shoulder_angle, self.RShoulderPitch.getMaxPosition()), self.RShoulderPitch.getMinPosition())
            self.RShoulderPitch.setPosition(left_shoulder_angle)  # Control right shoulder to mirror left hand
    
            # Код для ног, но робот падает
            
            # right_hip = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_HIP]
            # right_ankle = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_ANKLE]
           
            # right_hip_angle = (right_ankle.y - right_hip.y) * 3  # Scaling factor
            # right_hip_angle = max(min(right_hip_angle, self.LHipPitch.getMaxPosition()), self.LHipPitch.getMinPosition())
            # self.LHipPitch.setPosition(right_hip_angle)  # Control left hip to mirror right leg
    
            
            # left_hip = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_HIP]
            # left_ankle = result_pose.pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_ANKLE]
            
            # left_hip_angle = (left_ankle.y - left_hip.y) * 3  # Scaling factor
            # left_hip_angle = max(min(left_hip_angle, self.RHipPitch.getMaxPosition()), self.RHipPitch.getMinPosition())
            # self.RHipPitch.setPosition(left_hip_angle)  # Control right hip to mirror left leg
    
    
    
            # Draw pose landmarks for visualization
            # self.mp_draw.draw_landmarks(frame, result_pose.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)
    
        cv2.imshow('Pose Tracking', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            self.cap.release()
            cv2.destroyAllWindows()

    def run(self):
        while robot.step(self.timeStep) != -1:
            self.detectPoseGestures()  # Continuously check for pose gestures
            key = self.keyboard.getKey()
            if key > 0:
                break

# Create the Robot instance and run the main loop
robot = Nao()
robot.setNeutralArmPositions()
robot.run()
